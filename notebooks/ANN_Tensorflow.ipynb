{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "import datetime\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_transformed = pd.read_csv('../artifacts/resampled_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Exited\n",
       "0.0    7963\n",
       "1.0    7963\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_transformed.value_counts(subset='Exited')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.000008</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.008407</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.404654</td>\n",
       "      <td>4.004851</td>\n",
       "      <td>0.691556</td>\n",
       "      <td>1.719320</td>\n",
       "      <td>2.19386</td>\n",
       "      <td>2.000913</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>2.316549</td>\n",
       "      <td>2.008407</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.290840</td>\n",
       "      <td>3.909497</td>\n",
       "      <td>0.345778</td>\n",
       "      <td>1.719320</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>2.000913</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.000008</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.008407</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.194081</td>\n",
       "      <td>4.004851</td>\n",
       "      <td>2.766223</td>\n",
       "      <td>5.157960</td>\n",
       "      <td>2.19386</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.000008</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.008407</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.232396</td>\n",
       "      <td>3.718790</td>\n",
       "      <td>0.345778</td>\n",
       "      <td>3.438640</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>2.316549</td>\n",
       "      <td>2.008407</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.794759</td>\n",
       "      <td>4.100204</td>\n",
       "      <td>0.691556</td>\n",
       "      <td>1.719320</td>\n",
       "      <td>2.19386</td>\n",
       "      <td>2.000913</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15921</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>2.316549</td>\n",
       "      <td>2.008407</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.943300</td>\n",
       "      <td>4.644345</td>\n",
       "      <td>2.094961</td>\n",
       "      <td>3.438640</td>\n",
       "      <td>2.19386</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15922</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.30664</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.008407</td>\n",
       "      <td>6.830714</td>\n",
       "      <td>4.546338</td>\n",
       "      <td>1.364597</td>\n",
       "      <td>3.438640</td>\n",
       "      <td>2.19386</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15923</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.30664</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.008407</td>\n",
       "      <td>5.573062</td>\n",
       "      <td>4.767680</td>\n",
       "      <td>1.689552</td>\n",
       "      <td>1.719320</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>2.000913</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15924</th>\n",
       "      <td>2.000008</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.008407</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.518226</td>\n",
       "      <td>4.659981</td>\n",
       "      <td>2.961495</td>\n",
       "      <td>1.719320</td>\n",
       "      <td>2.19386</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15925</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>2.316549</td>\n",
       "      <td>2.008407</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.007480</td>\n",
       "      <td>3.071415</td>\n",
       "      <td>1.264890</td>\n",
       "      <td>6.108228</td>\n",
       "      <td>2.19386</td>\n",
       "      <td>2.000913</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15926 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              0        1         2         3         4         5         6  \\\n",
       "0      2.000008  0.00000  0.000000  2.008407  0.000000  6.404654  4.004851   \n",
       "1      0.000000  0.00000  2.316549  2.008407  0.000000  6.290840  3.909497   \n",
       "2      2.000008  0.00000  0.000000  2.008407  0.000000  5.194081  4.004851   \n",
       "3      2.000008  0.00000  0.000000  2.008407  0.000000  7.232396  3.718790   \n",
       "4      0.000000  0.00000  2.316549  2.008407  0.000000  8.794759  4.100204   \n",
       "...         ...      ...       ...       ...       ...       ...       ...   \n",
       "15921  0.000000  0.00000  2.316549  2.008407  0.000000  5.943300  4.644345   \n",
       "15922  0.000000  2.30664  0.000000  0.000000  2.008407  6.830714  4.546338   \n",
       "15923  0.000000  2.30664  0.000000  0.000000  2.008407  5.573062  4.767680   \n",
       "15924  2.000008  0.00000  0.000000  2.008407  0.000000  7.518226  4.659981   \n",
       "15925  0.000000  0.00000  2.316549  2.008407  0.000000  7.007480  3.071415   \n",
       "\n",
       "              7         8        9        10  Exited  \n",
       "0      0.691556  1.719320  2.19386  2.000913     1.0  \n",
       "1      0.345778  1.719320  0.00000  2.000913     0.0  \n",
       "2      2.766223  5.157960  2.19386  0.000000     1.0  \n",
       "3      0.345778  3.438640  0.00000  0.000000     0.0  \n",
       "4      0.691556  1.719320  2.19386  2.000913     0.0  \n",
       "...         ...       ...      ...       ...     ...  \n",
       "15921  2.094961  3.438640  2.19386  0.000000     1.0  \n",
       "15922  1.364597  3.438640  2.19386  0.000000     1.0  \n",
       "15923  1.689552  1.719320  0.00000  2.000913     1.0  \n",
       "15924  2.961495  1.719320  2.19386  0.000000     1.0  \n",
       "15925  1.264890  6.108228  2.19386  2.000913     1.0  \n",
       "\n",
       "[15926 rows x 12 columns]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = X_transformed['Exited']\n",
    "X_transformed = X_transformed.drop(columns=['Exited'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(X_transformed,y,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11868</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.30664</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.008407</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.356565</td>\n",
       "      <td>3.511356</td>\n",
       "      <td>0.706720</td>\n",
       "      <td>1.71932</td>\n",
       "      <td>2.19386</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7117</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>2.316549</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.008407</td>\n",
       "      <td>5.835582</td>\n",
       "      <td>2.955961</td>\n",
       "      <td>1.728890</td>\n",
       "      <td>1.71932</td>\n",
       "      <td>2.19386</td>\n",
       "      <td>2.000913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15128</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>2.316549</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.008407</td>\n",
       "      <td>5.928702</td>\n",
       "      <td>4.460576</td>\n",
       "      <td>0.835231</td>\n",
       "      <td>1.71932</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>2.000913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11730</th>\n",
       "      <td>2.000008</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.008407</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.447491</td>\n",
       "      <td>4.680078</td>\n",
       "      <td>3.457779</td>\n",
       "      <td>1.71932</td>\n",
       "      <td>2.19386</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15393</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.30664</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.008407</td>\n",
       "      <td>7.528698</td>\n",
       "      <td>3.537713</td>\n",
       "      <td>3.114688</td>\n",
       "      <td>1.71932</td>\n",
       "      <td>2.19386</td>\n",
       "      <td>2.000913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2180</th>\n",
       "      <td>2.000008</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.008407</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.715057</td>\n",
       "      <td>4.004851</td>\n",
       "      <td>2.420445</td>\n",
       "      <td>3.43864</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>2.000913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6879</th>\n",
       "      <td>2.000008</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.008407</td>\n",
       "      <td>6.880606</td>\n",
       "      <td>2.383840</td>\n",
       "      <td>2.420445</td>\n",
       "      <td>1.71932</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>2.000913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6220</th>\n",
       "      <td>2.000008</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.008407</td>\n",
       "      <td>8.349848</td>\n",
       "      <td>3.146668</td>\n",
       "      <td>3.457779</td>\n",
       "      <td>3.43864</td>\n",
       "      <td>2.19386</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14151</th>\n",
       "      <td>2.000008</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.008407</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.676227</td>\n",
       "      <td>3.438072</td>\n",
       "      <td>1.898549</td>\n",
       "      <td>3.43864</td>\n",
       "      <td>2.19386</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12806</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>2.316549</td>\n",
       "      <td>2.008407</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.928253</td>\n",
       "      <td>4.743394</td>\n",
       "      <td>2.023125</td>\n",
       "      <td>3.43864</td>\n",
       "      <td>2.19386</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12740 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              0        1         2         3         4         5         6  \\\n",
       "11868  0.000000  2.30664  0.000000  2.008407  0.000000  8.356565  3.511356   \n",
       "7117   0.000000  0.00000  2.316549  0.000000  2.008407  5.835582  2.955961   \n",
       "15128  0.000000  0.00000  2.316549  0.000000  2.008407  5.928702  4.460576   \n",
       "11730  2.000008  0.00000  0.000000  2.008407  0.000000  7.447491  4.680078   \n",
       "15393  0.000000  2.30664  0.000000  0.000000  2.008407  7.528698  3.537713   \n",
       "...         ...      ...       ...       ...       ...       ...       ...   \n",
       "2180   2.000008  0.00000  0.000000  2.008407  0.000000  6.715057  4.004851   \n",
       "6879   2.000008  0.00000  0.000000  0.000000  2.008407  6.880606  2.383840   \n",
       "6220   2.000008  0.00000  0.000000  0.000000  2.008407  8.349848  3.146668   \n",
       "14151  2.000008  0.00000  0.000000  2.008407  0.000000  4.676227  3.438072   \n",
       "12806  0.000000  0.00000  2.316549  2.008407  0.000000  5.928253  4.743394   \n",
       "\n",
       "              7        8        9        10  \n",
       "11868  0.706720  1.71932  2.19386  0.000000  \n",
       "7117   1.728890  1.71932  2.19386  2.000913  \n",
       "15128  0.835231  1.71932  0.00000  2.000913  \n",
       "11730  3.457779  1.71932  2.19386  0.000000  \n",
       "15393  3.114688  1.71932  2.19386  2.000913  \n",
       "...         ...      ...      ...       ...  \n",
       "2180   2.420445  3.43864  0.00000  2.000913  \n",
       "6879   2.420445  1.71932  0.00000  2.000913  \n",
       "6220   3.457779  3.43864  2.19386  0.000000  \n",
       "14151  1.898549  3.43864  2.19386  0.000000  \n",
       "12806  2.023125  3.43864  2.19386  0.000000  \n",
       "\n",
       "[12740 rows x 11 columns]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_transformed.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\Desktop\\ANN Project\\ANN_Project\\venv\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    keras.layers.Dense(128,activation='relu',input_shape =(X_train.shape[1],)),\n",
    "    keras.layers.Dense(64,activation='relu'),\n",
    "    keras.layers.Dense(32,activation='relu'),\n",
    "    keras.layers.Dense(16,activation='relu'),\n",
    "    keras.layers.Dense(8,activation='relu'),\n",
    "    keras.layers.Dense(1,activation='sigmoid')\n",
    "\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_6\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_6\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_24 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,536</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_25 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_26 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_27 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">528</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_28 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">136</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_29 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_24 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │         \u001b[38;5;34m1,536\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_25 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m8,256\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_26 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m2,080\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_27 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)             │           \u001b[38;5;34m528\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_28 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)              │           \u001b[38;5;34m136\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_29 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │             \u001b[38;5;34m9\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">12,545</span> (49.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m12,545\u001b[0m (49.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">12,545</span> (49.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m12,545\u001b[0m (49.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
    "    loss = keras.losses.binary_crossentropy,\n",
    "    metrics = ['accuracy','recall','f1_score','precision']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = 'logs/fit' + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorflow_callback = keras.callbacks.TensorBoard(log_dir=log_dir,histogram_freq=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = keras.callbacks.EarlyStopping(monitor=\"val_loss\",patience=5,restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 13ms/step - accuracy: 0.7977 - f1_score: 0.6682 - loss: 0.4247 - precision: 0.8070 - recall: 0.7849 - val_accuracy: 0.8001 - val_f1_score: 0.6675 - val_loss: 0.4446 - val_precision: 0.8021 - val_recall: 0.7976\n",
      "Epoch 2/50\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - accuracy: 0.7847 - f1_score: 0.6638 - loss: 0.4365 - precision: 0.7890 - recall: 0.7729 - val_accuracy: 0.8001 - val_f1_score: 0.6675 - val_loss: 0.4445 - val_precision: 0.8021 - val_recall: 0.7976\n",
      "Epoch 3/50\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.7993 - f1_score: 0.6653 - loss: 0.4262 - precision: 0.8054 - recall: 0.7884 - val_accuracy: 0.8001 - val_f1_score: 0.6675 - val_loss: 0.4445 - val_precision: 0.8021 - val_recall: 0.7976\n",
      "Epoch 4/50\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.7914 - f1_score: 0.6712 - loss: 0.4291 - precision: 0.8030 - recall: 0.7776 - val_accuracy: 0.8004 - val_f1_score: 0.6675 - val_loss: 0.4445 - val_precision: 0.8026 - val_recall: 0.7976\n",
      "Epoch 5/50\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.7955 - f1_score: 0.6697 - loss: 0.4212 - precision: 0.8059 - recall: 0.7821 - val_accuracy: 0.8004 - val_f1_score: 0.6675 - val_loss: 0.4444 - val_precision: 0.8026 - val_recall: 0.7976\n",
      "Epoch 6/50\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 12ms/step - accuracy: 0.7933 - f1_score: 0.6672 - loss: 0.4265 - precision: 0.8050 - recall: 0.7753 - val_accuracy: 0.8004 - val_f1_score: 0.6675 - val_loss: 0.4444 - val_precision: 0.8026 - val_recall: 0.7976\n",
      "Epoch 7/50\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.7974 - f1_score: 0.6710 - loss: 0.4244 - precision: 0.8089 - recall: 0.7839 - val_accuracy: 0.8001 - val_f1_score: 0.6675 - val_loss: 0.4443 - val_precision: 0.8021 - val_recall: 0.7976\n",
      "Epoch 8/50\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.7967 - f1_score: 0.6649 - loss: 0.4232 - precision: 0.8025 - recall: 0.7851 - val_accuracy: 0.8001 - val_f1_score: 0.6675 - val_loss: 0.4443 - val_precision: 0.8021 - val_recall: 0.7976\n",
      "Epoch 9/50\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.7951 - f1_score: 0.6692 - loss: 0.4239 - precision: 0.8080 - recall: 0.7773 - val_accuracy: 0.8001 - val_f1_score: 0.6675 - val_loss: 0.4443 - val_precision: 0.8025 - val_recall: 0.7970\n",
      "Epoch 10/50\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.7934 - f1_score: 0.6550 - loss: 0.4297 - precision: 0.7907 - recall: 0.7830 - val_accuracy: 0.8004 - val_f1_score: 0.6675 - val_loss: 0.4442 - val_precision: 0.8030 - val_recall: 0.7970\n",
      "Epoch 11/50\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - accuracy: 0.8015 - f1_score: 0.6656 - loss: 0.4162 - precision: 0.8082 - recall: 0.7893 - val_accuracy: 0.8004 - val_f1_score: 0.6675 - val_loss: 0.4442 - val_precision: 0.8030 - val_recall: 0.7970\n",
      "Epoch 12/50\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.7918 - f1_score: 0.6734 - loss: 0.4270 - precision: 0.8047 - recall: 0.7791 - val_accuracy: 0.8004 - val_f1_score: 0.6675 - val_loss: 0.4441 - val_precision: 0.8030 - val_recall: 0.7970\n",
      "Epoch 13/50\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.7945 - f1_score: 0.6633 - loss: 0.4340 - precision: 0.8036 - recall: 0.7755 - val_accuracy: 0.8004 - val_f1_score: 0.6675 - val_loss: 0.4441 - val_precision: 0.8030 - val_recall: 0.7970\n",
      "Epoch 14/50\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.7978 - f1_score: 0.6661 - loss: 0.4182 - precision: 0.8076 - recall: 0.7812 - val_accuracy: 0.8004 - val_f1_score: 0.6675 - val_loss: 0.4441 - val_precision: 0.8030 - val_recall: 0.7970\n",
      "Epoch 15/50\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.7964 - f1_score: 0.6728 - loss: 0.4228 - precision: 0.8100 - recall: 0.7815 - val_accuracy: 0.8007 - val_f1_score: 0.6675 - val_loss: 0.4440 - val_precision: 0.8035 - val_recall: 0.7970\n",
      "Epoch 16/50\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.7915 - f1_score: 0.6694 - loss: 0.4327 - precision: 0.8025 - recall: 0.7770 - val_accuracy: 0.8007 - val_f1_score: 0.6675 - val_loss: 0.4440 - val_precision: 0.8035 - val_recall: 0.7970\n",
      "Epoch 17/50\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - accuracy: 0.7988 - f1_score: 0.6704 - loss: 0.4213 - precision: 0.8116 - recall: 0.7829 - val_accuracy: 0.8007 - val_f1_score: 0.6675 - val_loss: 0.4440 - val_precision: 0.8035 - val_recall: 0.7970\n",
      "Epoch 18/50\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - accuracy: 0.7961 - f1_score: 0.6685 - loss: 0.4236 - precision: 0.8039 - recall: 0.7853 - val_accuracy: 0.8004 - val_f1_score: 0.6675 - val_loss: 0.4439 - val_precision: 0.8030 - val_recall: 0.7970\n",
      "Epoch 19/50\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.7947 - f1_score: 0.6648 - loss: 0.4299 - precision: 0.8007 - recall: 0.7824 - val_accuracy: 0.8004 - val_f1_score: 0.6675 - val_loss: 0.4439 - val_precision: 0.8030 - val_recall: 0.7970\n",
      "Epoch 20/50\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.7945 - f1_score: 0.6652 - loss: 0.4257 - precision: 0.8018 - recall: 0.7805 - val_accuracy: 0.8004 - val_f1_score: 0.6675 - val_loss: 0.4438 - val_precision: 0.8030 - val_recall: 0.7970\n",
      "Epoch 21/50\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.7946 - f1_score: 0.6696 - loss: 0.4210 - precision: 0.8035 - recall: 0.7834 - val_accuracy: 0.8004 - val_f1_score: 0.6675 - val_loss: 0.4438 - val_precision: 0.8030 - val_recall: 0.7970\n",
      "Epoch 22/50\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7937 - f1_score: 0.6659 - loss: 0.4299 - precision: 0.8020 - recall: 0.7788 - val_accuracy: 0.8004 - val_f1_score: 0.6675 - val_loss: 0.4438 - val_precision: 0.8030 - val_recall: 0.7970\n",
      "Epoch 23/50\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7910 - f1_score: 0.6640 - loss: 0.4321 - precision: 0.7958 - recall: 0.7797 - val_accuracy: 0.8004 - val_f1_score: 0.6675 - val_loss: 0.4437 - val_precision: 0.8030 - val_recall: 0.7970\n",
      "Epoch 24/50\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.7937 - f1_score: 0.6609 - loss: 0.4245 - precision: 0.7966 - recall: 0.7814 - val_accuracy: 0.8004 - val_f1_score: 0.6675 - val_loss: 0.4437 - val_precision: 0.8030 - val_recall: 0.7970\n",
      "Epoch 25/50\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.7959 - f1_score: 0.6662 - loss: 0.4238 - precision: 0.8026 - recall: 0.7839 - val_accuracy: 0.8004 - val_f1_score: 0.6675 - val_loss: 0.4437 - val_precision: 0.8030 - val_recall: 0.7970\n",
      "Epoch 26/50\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - accuracy: 0.7938 - f1_score: 0.6633 - loss: 0.4301 - precision: 0.7980 - recall: 0.7828 - val_accuracy: 0.8004 - val_f1_score: 0.6675 - val_loss: 0.4436 - val_precision: 0.8030 - val_recall: 0.7970\n",
      "Epoch 27/50\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.8008 - f1_score: 0.6657 - loss: 0.4203 - precision: 0.8088 - recall: 0.7866 - val_accuracy: 0.8004 - val_f1_score: 0.6675 - val_loss: 0.4436 - val_precision: 0.8030 - val_recall: 0.7970\n",
      "Epoch 28/50\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7935 - f1_score: 0.6702 - loss: 0.4291 - precision: 0.8051 - recall: 0.7789 - val_accuracy: 0.8004 - val_f1_score: 0.6675 - val_loss: 0.4436 - val_precision: 0.8030 - val_recall: 0.7970\n",
      "Epoch 29/50\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - accuracy: 0.7971 - f1_score: 0.6612 - loss: 0.4295 - precision: 0.8005 - recall: 0.7845 - val_accuracy: 0.8004 - val_f1_score: 0.6675 - val_loss: 0.4435 - val_precision: 0.8030 - val_recall: 0.7970\n",
      "Epoch 30/50\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.7949 - f1_score: 0.6604 - loss: 0.4323 - precision: 0.7984 - recall: 0.7809 - val_accuracy: 0.8004 - val_f1_score: 0.6675 - val_loss: 0.4435 - val_precision: 0.8030 - val_recall: 0.7970\n",
      "Epoch 31/50\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7933 - f1_score: 0.6597 - loss: 0.4289 - precision: 0.7942 - recall: 0.7829 - val_accuracy: 0.8004 - val_f1_score: 0.6675 - val_loss: 0.4435 - val_precision: 0.8030 - val_recall: 0.7970\n",
      "Epoch 32/50\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7904 - f1_score: 0.6569 - loss: 0.4352 - precision: 0.7931 - recall: 0.7723 - val_accuracy: 0.8001 - val_f1_score: 0.6675 - val_loss: 0.4434 - val_precision: 0.8025 - val_recall: 0.7970\n",
      "Epoch 33/50\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7925 - f1_score: 0.6643 - loss: 0.4247 - precision: 0.7998 - recall: 0.7775 - val_accuracy: 0.8001 - val_f1_score: 0.6675 - val_loss: 0.4434 - val_precision: 0.8025 - val_recall: 0.7970\n",
      "Epoch 34/50\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7995 - f1_score: 0.6549 - loss: 0.4191 - precision: 0.8011 - recall: 0.7827 - val_accuracy: 0.8001 - val_f1_score: 0.6675 - val_loss: 0.4434 - val_precision: 0.8025 - val_recall: 0.7970\n",
      "Epoch 35/50\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7956 - f1_score: 0.6658 - loss: 0.4236 - precision: 0.8012 - recall: 0.7852 - val_accuracy: 0.8001 - val_f1_score: 0.6675 - val_loss: 0.4433 - val_precision: 0.8025 - val_recall: 0.7970\n",
      "Epoch 36/50\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7971 - f1_score: 0.6692 - loss: 0.4202 - precision: 0.8072 - recall: 0.7836 - val_accuracy: 0.7997 - val_f1_score: 0.6675 - val_loss: 0.4433 - val_precision: 0.8020 - val_recall: 0.7970\n",
      "Epoch 37/50\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7925 - f1_score: 0.6702 - loss: 0.4292 - precision: 0.8017 - recall: 0.7815 - val_accuracy: 0.7997 - val_f1_score: 0.6675 - val_loss: 0.4433 - val_precision: 0.8020 - val_recall: 0.7970\n",
      "Epoch 38/50\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7880 - f1_score: 0.6641 - loss: 0.4282 - precision: 0.7968 - recall: 0.7697 - val_accuracy: 0.7994 - val_f1_score: 0.6675 - val_loss: 0.4432 - val_precision: 0.8019 - val_recall: 0.7964\n",
      "Epoch 39/50\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7915 - f1_score: 0.6735 - loss: 0.4293 - precision: 0.8041 - recall: 0.7791 - val_accuracy: 0.7991 - val_f1_score: 0.6675 - val_loss: 0.4432 - val_precision: 0.8018 - val_recall: 0.7957\n",
      "Epoch 40/50\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7956 - f1_score: 0.6659 - loss: 0.4206 - precision: 0.8051 - recall: 0.7795 - val_accuracy: 0.7988 - val_f1_score: 0.6675 - val_loss: 0.4432 - val_precision: 0.8016 - val_recall: 0.7951\n",
      "Epoch 41/50\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7931 - f1_score: 0.6689 - loss: 0.4311 - precision: 0.7998 - recall: 0.7848 - val_accuracy: 0.7988 - val_f1_score: 0.6675 - val_loss: 0.4431 - val_precision: 0.8016 - val_recall: 0.7951\n",
      "Epoch 42/50\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7961 - f1_score: 0.6665 - loss: 0.4262 - precision: 0.8014 - recall: 0.7872 - val_accuracy: 0.7985 - val_f1_score: 0.6675 - val_loss: 0.4431 - val_precision: 0.8015 - val_recall: 0.7945\n",
      "Epoch 43/50\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7957 - f1_score: 0.6621 - loss: 0.4293 - precision: 0.7995 - recall: 0.7837 - val_accuracy: 0.7985 - val_f1_score: 0.6675 - val_loss: 0.4431 - val_precision: 0.8015 - val_recall: 0.7945\n",
      "Epoch 44/50\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8011 - f1_score: 0.6679 - loss: 0.4211 - precision: 0.8086 - recall: 0.7905 - val_accuracy: 0.7985 - val_f1_score: 0.6675 - val_loss: 0.4430 - val_precision: 0.8015 - val_recall: 0.7945\n",
      "Epoch 45/50\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7925 - f1_score: 0.6651 - loss: 0.4315 - precision: 0.8039 - recall: 0.7717 - val_accuracy: 0.7988 - val_f1_score: 0.6675 - val_loss: 0.4430 - val_precision: 0.8016 - val_recall: 0.7951\n",
      "Epoch 46/50\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7935 - f1_score: 0.6614 - loss: 0.4288 - precision: 0.7975 - recall: 0.7799 - val_accuracy: 0.7988 - val_f1_score: 0.6675 - val_loss: 0.4430 - val_precision: 0.8016 - val_recall: 0.7951\n",
      "Epoch 47/50\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7978 - f1_score: 0.6656 - loss: 0.4187 - precision: 0.8053 - recall: 0.7845 - val_accuracy: 0.7988 - val_f1_score: 0.6675 - val_loss: 0.4429 - val_precision: 0.8016 - val_recall: 0.7951\n",
      "Epoch 48/50\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7951 - f1_score: 0.6636 - loss: 0.4262 - precision: 0.7993 - recall: 0.7843 - val_accuracy: 0.7988 - val_f1_score: 0.6675 - val_loss: 0.4429 - val_precision: 0.8016 - val_recall: 0.7951\n",
      "Epoch 49/50\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7949 - f1_score: 0.6587 - loss: 0.4260 - precision: 0.7946 - recall: 0.7854 - val_accuracy: 0.7988 - val_f1_score: 0.6675 - val_loss: 0.4429 - val_precision: 0.8016 - val_recall: 0.7951\n",
      "Epoch 50/50\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7921 - f1_score: 0.6766 - loss: 0.4276 - precision: 0.8106 - recall: 0.7745 - val_accuracy: 0.7988 - val_f1_score: 0.6675 - val_loss: 0.4428 - val_precision: 0.8016 - val_recall: 0.7951\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train,y_train,epochs=50,validation_data=(X_test,y_test),callbacks=[tensorflow_callback,early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-8fd4e60cd1928c0e\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-8fd4e60cd1928c0e\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6013;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir= logs/fit20250116-230641\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
